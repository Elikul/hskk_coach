{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path(\".\").parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"aishell3\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"processed\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AISHELL3_URL = \"http://www.openslr.org/resources/93/data_aishell3.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_aishell3():\n",
    "    \"\"\"Скачивает AISHELL-3, если ещё не скачан\"\"\"\n",
    "    tar_path = DATA_DIR / \"data_aishell3.tgz\"\n",
    "    if tar_path.exists():\n",
    "        print(\"AISHELL-3 архив уже скачан.\")\n",
    "        return tar_path\n",
    "\n",
    "    print(\"Скачивание AISHELL-3...\")\n",
    "    def reporthook(block_num, block_size, total_size):\n",
    "        if total_size > 0:\n",
    "            percent = min(100, (block_num * block_size * 100) // total_size)\n",
    "            print(f\"\\rПрогресс: {percent}%\", end=\"\")\n",
    "    urllib.request.urlretrieve(AISHELL3_URL, tar_path, reporthook)\n",
    "    print(\"\\nЗагрузка завершена.\")\n",
    "    return tar_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aishell3(tar_path: Path):\n",
    "    \"\"\"Распаковывает AISHELL-3\"\"\"\n",
    "    if (DATA_DIR / \"train\").exists() and (DATA_DIR / \"test\").exists():\n",
    "        print(\"AISHELL-3 уже распакован.\")\n",
    "        return\n",
    "\n",
    "    print(\"Распаковка...\")\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "        tar.extractall(DATA_DIR.parent)\n",
    "    # AISHELL-3 распаковывается в data_aishell3/train и data_aishell3/test\n",
    "    # Переместим содержимое в data/aishell3/\n",
    "    src_dir = DATA_DIR.parent / \"data_aishell3\"\n",
    "    if src_dir.exists():\n",
    "        for item in src_dir.iterdir():\n",
    "            shutil.move(str(item), str(DATA_DIR))\n",
    "        shutil.rmtree(src_dir)\n",
    "    print(\"Распаковка завершена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_aishell3_labels_from_content():\n",
    "    \"\"\"\n",
    "    Загружает слоги с тонами из content.txt.\n",
    "    Формат: <filename> <иероглифы> <пиньинь_с_тонами>\n",
    "    Пример: SSB00050001.wav\t广 guang3 州 zhou1 ...\n",
    "    \"\"\"\n",
    "    content_path = DATA_DIR / \"train\" / \"content.txt\"\n",
    "    if not content_path.exists():\n",
    "        raise FileNotFoundError(f\"Не найден {content_path}. Убедитесь, что AISHELL-3 распакован полностью.\")\n",
    "\n",
    "    labels = {}\n",
    "    with open(content_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            wav_filename = parts[0]  # Например, SSB00050001.wav\n",
    "            # Убираем .wav\n",
    "            wav_id = wav_filename.replace(\".wav\", \"\")\n",
    "            # Пиньинь с тонами начинаются после иероглифов — обычно с 2-го элемента\n",
    "            # Но лучше найти индекс, где начинается пиньинь\n",
    "            pinyin_start_idx = 1  # Первый элемент — имя файла, второй — первый иероглиф\n",
    "            # Пропускаем иероглифы — они идут до первого слова, содержащего цифру тона\n",
    "            for i in range(1, len(parts)):\n",
    "                if parts[i][-1].isdigit() and parts[i][:-1].isalpha():\n",
    "                    pinyin_start_idx = i\n",
    "                    break\n",
    "\n",
    "            syllables = parts[pinyin_start_idx:]\n",
    "            labels[wav_id] = syllables\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def extract_f0_for_syllables():\n",
    "    \"\"\"\n",
    "    Главная функция препроцессинга.\n",
    "    Извлекает F0 для каждого слога, используя грубую сегментацию по времени.\n",
    "    \"\"\"\n",
    "    labels = load_aishell3_labels_from_content()\n",
    "    wav_base_dir = DATA_DIR / \"train\" / \"wav\"\n",
    "\n",
    "    all_f0 = []\n",
    "    all_tones = []\n",
    "\n",
    "    print(\"Извлечение F0 для слогов...\")\n",
    "    random.seed(42)  # для воспроизводимости\n",
    "    sampled_items = random.sample(list(labels.items()), k=min(300, len(labels)))\n",
    "    \n",
    "    for wav_id, syllables in tqdm(sampled_items):\n",
    "        # Определяем путь к файлу: train/wav/SSB0005/SSB00050001.wav\n",
    "        speaker_id = wav_id[:7]  # первые 7 символов: SSB0005\n",
    "        wav_path = wav_base_dir / speaker_id / f\"{wav_id}.wav\"\n",
    "        \n",
    "        if not wav_path.exists():\n",
    "            print(f\"Не найден файл: {wav_path}\")\n",
    "            continue\n",
    "\n",
    "        # Загружаем аудио\n",
    "        y, sr = librosa.load(wav_path, sr=16000)\n",
    "        duration = len(y) / sr\n",
    "        n_syllables = len(syllables)\n",
    "\n",
    "        # Делим аудио на n_syllables равных частей\n",
    "        for i, syl in enumerate(syllables):\n",
    "            start = i * duration / n_syllables\n",
    "            end = (i + 1) * duration / n_syllables\n",
    "\n",
    "            # Извлекаем F0 с помощью Pyin\n",
    "            y_seg = y[int(start * sr):int(end * sr)]\n",
    "            if len(y_seg) == 0:\n",
    "                continue\n",
    "\n",
    "            f0, _, _ = librosa.pyin(\n",
    "                y_seg,\n",
    "                fmin=librosa.note_to_hz('C2'),   # ~65 Гц\n",
    "                fmax=librosa.note_to_hz('C7'),   # ~2093 Гц\n",
    "                sr=sr,\n",
    "                frame_length=512,\n",
    "                win_length=512 // 2,\n",
    "                hop_length=128\n",
    "            )\n",
    "\n",
    "            # Оставляем только валидные значения\n",
    "            f0 = f0[~np.isnan(f0)]\n",
    "            if len(f0) < 5:  # слишком мало точек\n",
    "                continue\n",
    "\n",
    "            # Нормализуем контур до 50 точек\n",
    "            x_old = np.linspace(0, 1, len(f0))\n",
    "            x_new = np.linspace(0, 1, 50)\n",
    "            f0_interp = np.interp(x_new, x_old, f0)\n",
    "\n",
    "            # Преобразуем тон из 'ni3' → 3\n",
    "            if syl[-1].isdigit():\n",
    "                tone = int(syl[-1])\n",
    "            else:\n",
    "                tone = 5  # нейтральный\n",
    "\n",
    "            all_f0.append(f0_interp)\n",
    "            all_tones.append(tone)\n",
    "\n",
    "    # Сохраняем\n",
    "    np.save(PROCESSED_DIR / \"f0_contours.npy\", np.array(all_f0))\n",
    "    np.save(PROCESSED_DIR / \"tones.npy\", np.array(all_tones))\n",
    "    print(f\"Обработано {len(all_f0)} слогов.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлечение F0 для слогов...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]C:\\Users\\elina\\AppData\\Local\\Temp\\ipykernel_15688\\1018915623.py:5: FutureWarning: The win_length parameter has been deprecated in version 0.11.0 and has no effect. It will be removed in version 1.0.0.\n",
      "  extract_f0_for_syllables()\n",
      "100%|██████████| 300/300 [25:06<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 5044 слогов.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#tar_path = download_aishell3()\n",
    "#extract_aishell3(tar_path)\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "extract_f0_for_syllables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path(\".\").parent\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"processed\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToneCNN(nn.Module):\n",
    "    def __init__(self, input_len=50, num_classes=5):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * (input_len // 4), 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # (B, L) -> (B, 1, L)\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "X = np.load(PROCESSED_DIR / \"f0_contours.npy\")\n",
    "y = np.load(PROCESSED_DIR / \"tones.npy\") - 1  # тоны 1-5 → индексы 0-4\n",
    "\n",
    "# Нормализация: Z-score по каждому контуру\n",
    "X = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# Разделение\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Веса классов\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Датасеты\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                torch.tensor(y_train, dtype=torch.long))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                            torch.tensor(y_val, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# Модель\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)\n",
    "model = ToneCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 32/32 [00:00<00:00, 67.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6124, Val Acc: 0.1754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 32/32 [00:00<00:00, 104.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6075, Val Acc: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 32/32 [00:00<00:00, 106.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6048, Val Acc: 0.2418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 32/32 [00:00<00:00, 106.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6025, Val Acc: 0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 32/32 [00:00<00:00, 108.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5993, Val Acc: 0.1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 32/32 [00:00<00:00, 105.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5956, Val Acc: 0.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 32/32 [00:00<00:00, 91.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5891, Val Acc: 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 32/32 [00:00<00:00, 102.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5839, Val Acc: 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 32/32 [00:00<00:00, 106.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5756, Val Acc: 0.1288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 32/32 [00:00<00:00, 87.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5718, Val Acc: 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 32/32 [00:00<00:00, 100.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5687, Val Acc: 0.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 32/32 [00:00<00:00, 105.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5574, Val Acc: 0.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 32/32 [00:00<00:00, 108.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5532, Val Acc: 0.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 32/32 [00:00<00:00, 109.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5464, Val Acc: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 32/32 [00:00<00:00, 106.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5429, Val Acc: 0.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 32/32 [00:00<00:00, 109.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5324, Val Acc: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 32/32 [00:00<00:00, 105.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5162, Val Acc: 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 32/32 [00:00<00:00, 106.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5065, Val Acc: 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 32/32 [00:00<00:00, 108.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4983, Val Acc: 0.1487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 32/32 [00:00<00:00, 107.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4870, Val Acc: 0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 32/32 [00:00<00:00, 89.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4839, Val Acc: 0.1625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 32/32 [00:00<00:00, 107.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4691, Val Acc: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 32/32 [00:00<00:00, 102.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4577, Val Acc: 0.1615\n",
      "Ранняя остановка сработала.\n",
      "Модель сохранена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Параметры ранней остановки\n",
    "patience = 20\n",
    "best_val_acc = 0.0\n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "\n",
    "# Обучение\n",
    "for epoch in range(150):\n",
    "    if early_stop:\n",
    "        print(\"Ранняя остановка сработала.\")\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out.argmax(dim=1)\n",
    "            total += y.size(0)\n",
    "            correct += (pred == y).sum().item()\n",
    "    val_acc = correct / total\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Ранняя остановка\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        # Опционально: сохранять лучшую модель\n",
    "        torch.save(model.state_dict(), MODELS_DIR / \"tone_cnn_best.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            early_stop = True\n",
    "\n",
    "# Сохранение финальной модели\n",
    "torch.save(model.state_dict(), MODELS_DIR / \"tone_cnn.pth\")\n",
    "print(\"Модель сохранена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Тестирование и сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToneCNN(\n",
       "  (conv1): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (relu): ReLU()\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка модели и данных\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ToneCNN()\n",
    "model.load_state_dict(torch.load(MODELS_DIR / \"tone_cnn.pth\", map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(PROCESSED_DIR / \"f0_contours.npy\")\n",
    "y_true = np.load(PROCESSED_DIR / \"tones.npy\") - 1  # 0-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация\n",
    "X = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-8)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    y_pred = outputs.argmax(dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Tone 1       0.29      0.39      0.33       539\n",
      "      Tone 2       0.21      0.50      0.29       583\n",
      "      Tone 3       0.19      0.45      0.27       396\n",
      "      Tone 4       0.24      0.45      0.31       881\n",
      "      Tone 5       0.75      0.10      0.18      2645\n",
      "\n",
      "    accuracy                           0.27      5044\n",
      "   macro avg       0.34      0.38      0.28      5044\n",
      "weighted avg       0.51      0.27      0.24      5044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"Tone 1\", \"Tone 2\", \"Tone 3\", \"Tone 4\", \"Tone 5\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
